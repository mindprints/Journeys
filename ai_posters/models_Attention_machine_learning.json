{
  "version": 2,
  "type": "poster-v2",
  "uid": "48ea6850-66bf-439a-9c91-037883568e67",
  "front": {
    "title": "Attention (machine learning)",
    "subtitle": "Machine learning technique"
  },
  "back": {
    "layout": "image-top",
    "text": "In machine learning, attention is a method that determines the importance of each component in a sequence relative to the other components in that sequence. In natural language processing, importance is represented by \"soft\" weights assigned to each word in a sentence. More generally, attention encodes vectors called token embeddings across a fixed-width sequence that can range from tens to millions of tokens in size.",
    "links": [
      {
        "type": "external",
        "label": "Read more on Wikipedia",
        "url": "https://en.wikipedia.org/wiki/Attention_(machine_learning)",
        "primary": true
      }
    ],
    "image": {
      "src": "https://upload.wikimedia.org/wikipedia/commons/thumb/6/62/Attention_mechanism_overview.svg/330px-Attention_mechanism_overview.svg.png",
      "alt": "Attention (machine learning)",
      "position": "top"
    }
  },
  "meta": {
    "created": "2026-02-10T13:20:14.308012",
    "modified": "2026-02-10T13:20:14.308016",
    "categories": [
      "AI Models",
      "Machine Learning"
    ],
    "tags": [
      "Attention (machine learning)"
    ],
    "source": "https://en.wikipedia.org/wiki/Attention_(machine_learning)"
  }
}